# Project Evaluation and Design Feedback: Git AST

_This document contains a detailed evaluation of the initial "Git AST" concept and feedback that has informed the current architecture and roadmap._

## Evaluating the "Git AST" Project: AST-Based Version Control with Tree-sitter and Git

### Introduction

"Git AST" is a conceptual version control system that tracks code changes as transformations of Abstract Syntax Trees (ASTs) rather than raw text diffs. In this model, source files are parsed (using Tree-sitter for multi-language support) and stored in a structured form, with Git's storage and history mechanisms as the backend. The goal is to make diffs and merges semantic – focusing on code structure and meaning – instead of line-by-line textual changes. This promises to eliminate spurious diffs (like purely formatting changes) and handle code refactorings (moves, renames, etc.) more intelligently. However, moving from line-based VCS to AST-based versioning introduces significant complexity. This report provides a critical evaluation of the Git AST approach, covering prior art in semantic version control, feasibility and engineering effort, architectural trade-offs, developer experience implications, and the key risks that could make or break the project. We also consider possible adjustments or alternative approaches to achieve the goals with fewer pitfalls.

### 1. Comparative Research: AST-Based Version Control & Related Tools

AST-based version control is an ambitious idea, and there have been several adjacent efforts in industry and research. These range from semantic diff/merge tools that improve upon textual diffs, to alternative VCS designs, to filesystem hacks for representing structured code. Below, we survey comparable projects and tools, highlighting their approaches, strengths, limitations, and lessons for "Git AST."

- Plastic SCM – Semantic Merge: Plastic SCM (now Unity VCS) offers a SemanticMerge tool, which uses language-specific parsers to perform merges at the code structure level. It parses files (initially C#, Java, etc.) and identifies changes to classes, methods, etc., rather than line blocks . SemanticMerge can detect additions, deletions, moves, and renames of code elements . This enables auto-merging many refactoring scenarios that would confuse text-based merge. For example, it can automatically merge the case where a method is moved in one branch and edited in another, or when one branch reformats code while another branch makes a functional change . This dramatically reduces manual conflicts on structured changes. The tool provides visual diffs highlighting structural edits (like method-level changes) instead of simple line diffs. Key strengths: It proves the benefit of AST-awareness in merges – fewer false conflicts and clearer diffs for certain languages. Limitations: SemanticMerge requires a custom parser for each language and currently supports only a handful (C#, Java, VB.NET, C, with experimental JavaScript) . It falls back to text-based merge for unsupported files . This limited language support and the need to constantly update parsers is a maintenance burden. Adoption has been niche – it's a proprietary tool mostly used by Plastic SCM users, and integration with Git or other VCS is possible but not built-in (users can configure SemanticMerge as an external merge tool for Git) . The takeaway is that semantic merging is feasible and beneficial, but implementing and maintaining it across many languages is challenging. It also shows that AST merges don't come for free – a lot of engineering (and user $) went into making it work for a few popular languages, and even then developers must adapt to a new merge tool workflow.
- Difftastic (and diffsitter) – AST Difftools: Difftastic is an open-source structural diff tool that uses Tree-sitter to parse source code and produce side-by-side diffs aware of syntax . Unlike a normal git diff, which treats every changed line as an insertion/deletion, difftastic understands nesting and ignores unimportant differences. For example, it will not mark a function body as entirely changed just because an if block was added around existing code; it knows those lines moved inside a new block and aligns them accordingly . It highlights real content changes (e.g. a literal changed from 1 to 2) while ignoring purely cosmetic changes like different indentation or line breaks . Figure 1 below shows an example: difftastic aligns the call bar(1) with bar(2) as corresponding code, even though the surrounding context shifted.

Figure 1: Example output from difftastic, an AST-aware diff tool. It recognizes when code is merely re-indented (here by adding an if(true) block on the right) and aligns the matching pieces. Only meaningful changes are highlighted (e.g. 1 → 2 in the bar() call), whereas a traditional diff would show many lines changed due to added braces and indent.

Another similar tool is diffsitter, also built on Tree-sitter, with the goal of ignoring formatting differences by diffing ASTs. These tools demonstrate the power of semantic diffs: they reduce noise (ignoring whitespace, comments, or reordered code that doesn't change behavior) and highlight actual code changes. They support dozens of languages (difftastic handles 30+ languages via Tree-sitter) . However, they also reveal challenges: difftastic notes performance issues on large diffs (many changes) and high memory usage . Its side-by-side output, while more informative, can sometimes be confusing for complex changes . Crucially, difftastic is read-only: it does not produce patch files or do merges . In fact, the author explicitly states that generating editable patches or performing merges is out of scope, calling AST merging "a hard problem" . In case of parse failures (e.g. code that Tree-sitter can't parse), difftastic will even fall back to a classic text diff . Key takeaways: AST-based diffs are already being used to improve developer insight, but they operate as adjunct tools rather than core version control. They show that integrating AST parsing into diff is possible across many languages (thanks to Tree-sitter), but the approach must gracefully handle parse errors and edge cases (e.g. by falling back to text diff) . Also, without an AST merge capability, these tools don't fully solve conflicts – they just help visualize changes. This suggests that a full AST-based VCS must tackle merging carefully (something even advanced diff tools avoid).

- GumTree – Academic AST Differencing: GumTree is a well-known AST differencing algorithm from research . It computes an edit script (add, delete, update, move operations on tree nodes) to transform one AST to another. GumTree can detect code moves and renamings that textual diff would miss . For example, if a function is moved from one file to another or a block of code is rearranged, GumTree will output that as a "move" operation rather than a deletion in one place and an insertion in another. This yields a more accurate representation of changes. GumTree and similar algorithms (e.g. ChangeDistiller, etc.) have been used in many research tools and even industrial prototypes for semantic analysis of code changes. Strengths: Fine-grained change detection (including updates to identifiers or literals, and moved code) which maps more directly to refactorings. Limitations: These algorithms can be expensive for large ASTs (they often have to compute tree matching with heuristics to identify moved subtrees). They may also struggle if the AST differences are very large (many nodes changed) – performance can degrade, as also noted with difftastic. Additionally, raw AST edit scripts are not very user-friendly for developers to read; they usually need to be presented in a higher-level format or visualized. GumTree's concepts have influenced practical tools (for example, IntelliJ's structural diff and some refactoring-aware merge tools use similar ideas for Java code). The lesson is that the theory for AST diff/merge exists and shows clear benefits (e.g. distinguishing a rename or move from an addition/deletion). Any "Git AST" implementation can leverage these algorithms but must also manage their complexity and ensure they integrate into a smooth user workflow.
- Pijul and Alternative VCS Patch Models: Pijul is a modern DVCS that, unlike Git, isn't line-based – it's built on a theory of patches (in fact, the same mathematics as Darcs). Pijul's approach is not AST-based, but it's worth noting because it highlights alternative ways to handle merges and conflicts. Pijul stores changes as independent patches that can commute; it models conflicts explicitly in the history . In a discussion on the Pijul forum, it was noted that Pijul could potentially incorporate AST diff algorithms on top of its patch theory for even smarter merges . The key point here is that even without ASTs, some VCS try to be smarter than Git about merges (Pijul can merge changes to the same line in some cases by treating file content more granularly than line chunks). However, Pijul's approach is still ultimately operating on text substrings, not a parsed AST. It helps reduce certain conflicts but does not resolve semantic conflicts like renaming a variable (which an AST-aware merge could handle by recognizing it's the same symbol renamed). The relative lack of widespread adoption of Pijul (and Darcs) also underscores that any new VCS paradigm faces an uphill battle against Git's network effects, unless it can integrate or offer compelling advantages. For Git AST, using Git's backend is an attempt to leverage Git's popularity, but if the workflow diverges too much, it might face similar adoption challenges.
- Filesystem and Editor Integrations (FUSE, etc.): Some proposals suggest making AST-based version control transparent to developers by integrating at the filesystem or editor level. One idea (floated in online discussions) is to use a FUSE filesystem to present a "virtual" source code view backed by AST storage . For example, the repository could store files as serialized ASTs (or some canonical format), but developers would mount a FUSE FS that generates the human-readable source code on the fly. In such a setup, editing a file module1.txt through the FUSE mount would actually update module1.ast behind the scenes, and vice-versa . This approach could let developers use their normal editors and tools on code as text, while the system handles parsing and storing the structured version automatically. Strengths: Transparent workflow – developers might not even realize the code is stored differently, since they see normal code files. It could also enable interesting features like letting each user choose a presentation style (since the "view" is generated, one user could mount the repo with a style that omits semicolons or uses different indentation, satisfying personal preferences as suggested in a Prettier issue discussion ). Limitations: A FUSE-based solution introduces complexity and latency at the filesystem level. Every file read/write goes through the parsing or printing process, which could slow down builds and editor operations if not highly optimized. Synchronization bugs and edge cases (what if two processes edit concurrently, etc.) could arise . It's also quite tricky to implement correctly – essentially building a bidirectional live view of code and AST. There's scant evidence of successful large-scale uses of this approach; it's mostly hypothetical (one HN commenter noted "I think I've seen this in some experimental language", implying it's far from mainstream). Another approach is editor integration: e.g. a plugin that on file save converts the buffer to AST and commits it. This avoids FUSE but limits use to certain editors/IDEs. Overall, while FUSE/editor tricks could hide the AST mechanics from developers, they add their own maintenance and performance burdens. The lack of established tools in this space means Git AST would be breaking new ground integrating at this level.

Summary Comparison: Table 1 compares some of these existing tools and approaches relevant to Git AST:

| Tool / Approach           | Method                                                                                 | Strengths                                                                                                                                   | Limitations / Status                                                                                                                                                                 |
| ------------------------- | -------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Plastic SCM SemanticMerge | External AST parser + 3-way merge for each supported language.                         | Handles method moves, renames, and reformatting merges automatically . Reduces merge conflicts significantly.                               | Limited to a few languages (C#, Java, etc.) . Proprietary tool; not widely adopted outside Unity/Plastic. Requires continual grammar updates for each language.                      |
| Difftastic (Open Source)  | Tree-sitter parses code; structural 2-way diff (no merging) .                          | Ignores whitespace/format diffs; aligns changes by AST structure (30+ languages) . Can be used as Git diff viewer for clearer code reviews. | No patch output or merging support . High memory usage on large changes . Still evolving; needs custom integration in editors/CI (not default). Falls back to text on parse errors . |
| GumTree (Research)        | AST differencing algorithm producing edit scripts.                                     | Detects fine-grained edits and moves (not just adds/deletes) . Forms theoretical basis for refactoring-aware merges.                        | Algorithmic complexity on large ASTs. Output is low-level (needs tooling to visualize). Primarily academic – requires integration into a VC or tool to be useful.                    |
| Pijul (Patch-based VCS)   | Stores changes as atomic patches, not line diffs .                                     | More flexible merging than Git's line-based approach; built-in conflict recording. Potential to incorporate AST strategies on top .         | Not inherently AST-aware; still operates on text. Small community and ecosystem compared to Git. Switching VCS has major adoption hurdles.                                           |
| FUSE/Virtual FS for AST   | Custom filesystem or editor plugin that presents AST-backed files as normal code text. | Could make AST storage invisible to developers; possibly allow customized code views per user.                                              | Complex to implement and potentially slow (overhead on file operations) . Risk of sync issues. No off-the-shelf solution; an experimental area.                                      |

Key Lessons: These efforts show real benefits to semantic diffs/merges – e.g. fewer merge conflicts and clearer diffs when using ASTs instead of plain text. For instance, an academic structured merge tool (IntelliMerge) reduced merge conflicts by ~59% compared to Git's unstructured merge in evaluations . However, they also demonstrate the significant engineering effort to support multiple languages and the performance challenges of AST operations at scale. The adoption of AST-based methods has been limited so far: developers value them (e.g. as optional diff tools or merge aids) but have not replaced their core version control with an AST-based system yet. "Git AST" would in effect attempt to be the first practical, general AST-centric VCS by building on Git's foundation. It can draw on prior work (parsers from Tree-sitter, algorithms like GumTree, merge concepts from SemanticMerge) but must also avoid the pitfalls (limited language support, slow operations, complex integration) that have hindered broader adoption in the past.

### 2. Feasibility and Work Estimates for a Git AST MVP

Building a "Git AST" system is a non-trivial engineering project. It essentially combines components of a compiler (parsing and pretty-printing code), a version control system, and possibly filesystem or editor integration. Below we break down the major components of a minimum viable product (MVP), estimate the effort for each, and identify especially challenging aspects. We assume the MVP goal is: support a basic end-to-end workflow for one or two languages – i.e. parse source files into ASTs, store them in Git (with some mapping to Git objects/commits), show AST-based diffs of changes, and regenerate source code from the AST for editing or build purposes. Full multi-language support and advanced merging would be beyond the MVP, but we'll consider them in planning phases.

Major Engineering Components:

1.  **Parsing and AST Generation:**

    - Integrate Tree-sitter or similar to parse source files into ASTs.
    - MVP: Focus on one language (e.g., Python or JavaScript), bundle its Tree-sitter grammar.
    - Work needed: Embed the parser, handle errors (Tree-sitter can produce partial ASTs), decide on AST storage format (JSON, S-expressions, binary).
    - _Estimate:_ A few weeks for basic integration (one language). Supporting multiple languages adds significant effort (~1 month for 2 languages, including testing). Maintenance of grammars is an ongoing concern.

2.  **Mapping AST to Git Storage:**

    - Design how the AST will be stored in Git's object model.
    - Options:
      - (a) Serialize each file's AST into a single Git blob (simpler, MVP approach).
      - (b) Break the AST into many small pieces (e.g., node/function per blob, using Git trees - more complex, potential delta-compression benefits).
    - Work needed: Choose a deterministic serialization format. Implement clean/smudge filters _or_ a custom CLI/tooling to handle conversion between source <-> AST blob.
    - _Estimate:_ A few weeks for design. Option (a) is straightforward, but ensuring consistency/efficiency is key. Implementing robust storage conversion (e.g., clean/smudge filters) might take ~4–6 weeks, including testing basic operations (commit, checkout, diff).

3.  **AST Diff and Display:**

    - Implement an AST-based differ to show structural changes.
    - MVP: Utilize existing algorithms/tools (difftastic, GumTree) or implement a simple structural diff (e.g., LCS on nodes, ignoring formatting). Showing a text diff of serialized AST (e.g., JSON) is noisy and not ideal.
    - Work needed: Integrate or implement an AST differ, format the output readably.
    - _Estimate:_ Integrating an existing library: ~1-2 weeks. Writing from scratch: several weeks. Basic diff view for one language: ~3 weeks (including testing).

4.  **Code Generation (Pretty-Printing):**

    - Regenerate source code from the AST (for working directory, compilers, linters).
    - Options:
      - Implement a custom pretty-printer/unparser per language (complex).
      - Store original formatting/tokens alongside AST (easier round-trip, but AST isn't fully canonical).
      - Enforce a standard code format using existing tools (e.g., Prettier, Black, gofmt) - _preferred MVP path_.
    - Work needed: Integrate existing formatters or build custom ones. Crucially, ensure comments are preserved and reinserted correctly.
    - _Estimate:_ Relying on existing formatters: ~2 weeks integration per formatter. Writing custom pretty-printer: many weeks per language.

5.  **CLI and/or Integration Layer:**
    - Provide a user interface: custom CLI (`gitast add`, `gitast diff`) or transparent integration (Git smudge/clean filters, FUSE).
    - MVP: A simple custom CLI wrapping Git might be quickest.
    - Alternatives:
      - Git smudge/clean filters: More seamless integration, but filters have complexities (performance, setup).
      - FUSE filesystem: Most transparent, but significant complexity, likely post-MVP.
    - Work needed: Implement chosen interface (CLI commands, filter scripts, FUSE logic).
    - _Estimate:_ Basic CLI wrapper: ~2 weeks. Git filter approach: a few weeks for robust implementation/testing. FUSE integration: ~1-2 months.

Integration & Testing: After building these components, there's a need for integration testing across the workflow: edit a code file → AST commit → modify again → diff → merge two branches, etc. Debugging issues (e.g. if the pretty-printer output doesn't round-trip back into the same AST, or if Git's delta compression of AST blobs is poor) will take time. Realistically, an MVP with one language, basic diff, and no fancy merge automation could take on the order of 3–6 months of development by an experienced engineer. Expanding to multiple languages and adding robust merging could easily extend it to 12+ months for a small team.

We should also break down phases beyond MVP:
• Phase 1: Single-language prototype – Get the full cycle working for, say, Python. Parse on commit, store AST (perhaps as JSON blob), able to diff and reconstruct code. No branch merging yet beyond what Git does (which would merge the JSON text – likely not meaningful, so we'd avoid complex merges in this phase). This phase proves out the core AST storage and diff concepts.
• Phase 2: Basic Merging – Introduce an AST-aware merge driver. This means when two branches diverge, instead of Git's line merge, use an AST 3-way merge (perhaps using a GumTree-based 3-way merge or a custom algorithm). This is quite complex because you have to match nodes from base to both sides and merge or flag conflicts in subtrees. A simple implementation might just use Git's text merge on the serialized AST (which won't be great). A better one could detect if the changes are in distinct parts of the AST and merge automatically. This phase would also need a strategy for conflicts: present conflicts in a way developers can resolve (maybe falling back to text conflict markers inside code, or a specialized conflict editor). Estimated effort: another few months of R&D; merging is likely one of the hardest parts.
• Phase 3: Multi-language support – Expand to more Tree-sitter grammars. This will expose issues like needing a mapping from file extension to parser, handling files that fail parsing (maybe binary files or unknown files should be stored as-is without AST). It also increases testing and maintenance overhead. Each new language might bring edge cases (e.g. C++ with macros might parse weirdly, or languages with significant whitespace like Python need careful handling to ensure AST respects indent meaning, etc.). Ongoing effort: continuous, but adding a new well-supported Tree-sitter grammar could be a week or two each in best case, plus potential long-term maintenance.
• Phase 4 (Optional): FUSE/Transparent FS or Editor Plugin – Once the core system is stable and proven, implement a background service that mounts the repository so developers can edit without learning new commands. This requires rigorous handling of file events: on file save, trigger parse and update AST; on git checkout or switch, update the view; on new commits, refresh, etc. Performance tuning (caching ASTs in memory to avoid re-parsing too often, etc.) would be critical. Effort: easily 2+ months to get a working FUSE prototype and more to make it production quality on multiple OSes.

Unexpected Hard & Performance-Sensitive Parts: Several components are likely to be trickier than they appear:
• AST Identity & Diff Complexity: Matching AST nodes between versions is not trivial. If a developer renames a variable or moves a function, how do we recognize it's the "same" node moved vs a delete+add? Tools like GumTree use heuristics (e.g. compute hashes of subtrees, compare identifiers) to guess matches. Implementing this ourselves could be bug-prone. Without good AST matching, the diffs and merges could become unreliable (e.g., falsely identifying a move as two separate changes). This part is both algorithmically complex (possibly O(n^2) comparisons for n nodes naively) and performance-sensitive for large files. We might need to optimize by caching node IDs or using node position + content as a pseudo-identity. Risk: This could consume significant time and still occasionally get it wrong, causing weird diff outputs. It's an area to possibly leverage existing libraries or simplify initial expectations (maybe MVP just doesn't detect moves, marking them as remove+add is acceptable for a start).
• FUSE Filesystem Performance: If we go the FUSE route, every file read and write might incur parsing or printing. Tree-sitter is fast (it can parse thousands of lines per second), but doing it on every keystroke or file save could add latency. Moreover, FUSE itself introduces overhead – context switching between kernel and user space. There's also the concern of directory listing performance if AST is split into many objects: e.g., if representing an AST as a deep directory tree of nodes, listing that directory (or doing a git status that scans many small files) could be extremely slow. Git itself struggles if a repo has hundreds of thousands of files; operations like status or checkout degrade with that many entries . If an AST for one source file were stored as, say, thousands of small files (one per AST node), we could easily hit performance walls. Even 100k files in one directory is enough to significantly slow down operations on many filesystems . So we likely will avoid that and store AST per file (to keep file count similar to normal). Still, FUSE might need caching: e.g., keep an in-memory AST and only reparse when the file is written, not on every read. Tuning this will be critical to avoid a laggy developer experience.
• Handling Partial Parses & Errors: In normal git, you can commit anything, even code that doesn't compile or is half-written. In an AST world, what do we do if the code doesn't parse? This is unexpectedly tricky: we either have to refuse the commit (forcing the user to fix syntax before commit, which is a new constraint), or we need some way to store an "incomplete AST" or fallback to raw text for that revision. Neither is great: refusing commit breaks the workflow of saving WIP, and storing raw text when parse fails complicates the model (the system would then need to detect that and perhaps later "upgrade" that commit once the code is fixed?). Perhaps the MVP can stipulate that code must parse to be versioned (which is usually true at merge time, but not always for intermediate commits). This is both an engineering and UX challenge. We might implement a fallback where if Tree-sitter returns an error node, we still serialize the partial AST (Tree-sitter does produce an AST with error nodes) and allow it. But then diffing or merging that might be unreliable. This is a hard corner-case to get right.
• Maintaining Formatting/Comments: It might come as a surprise how hard it is to round-trip code with full fidelity. Many ASTs drop non-semantic tokens. If we don't store them, we must re-insert them through formatting rules, which might not reproduce the original style. For MVP, maybe we intentionally normalize formatting (e.g., always output a standardized style). But for wider adoption, eventually users will expect that checking out a commit returns exactly what they wrote (especially for things like spacing in comments, or particular alignment in a table of values, etc.). Achieving lossless serialization of source code via AST is challenging. We might need to store extra metadata (like positions or the original text of each token) in order to reconstruct exactly. Tree-sitter is a parser, not a pretty-printer; it doesn't give an easy way to get the original text back apart from storing offsets into the original source. If we opt to always pretty-print, we have to accept that the tool essentially imposes a code style (like Prettier does). That could be unexpectedly controversial or problematic if the style conflicts with some parts of code (and some languages or projects don't have good pretty-printers, meaning we'd effectively force one or risk altering code meaning if the printer is imperfect).

In summary, an MVP is feasible in the sense that no piece is purely theoretical – we have parser libraries, diff algorithms, and Git itself to piggyback on. But it's a lot of work: on the order of several person-months for a limited prototype, and likely a year+ for a more complete multi-language version with merging and polished UX. Key areas like AST diff algorithms, performance optimizations, and multi-language support will require deep expertise and could become time sinks. Early identification of "make or break" technical challenges (like parse round-trips and identity mapping) is important so the team can either simplify the design or allocate extra time to them.

### 3. Constraints and Trade-offs (Architecture & Performance)

Adopting an AST-based storage and diff approach introduces several architectural constraints and forces trade-offs that don't arise in line-based systems. Here we discuss the most significant ones, including storage considerations, AST fidelity vs. simplicity, determinism and correctness of code generation, and maintainability concerns.
• Storage Strategy – Many Small Objects vs. Large Blobs: As mentioned, we have a fundamental design choice: do we break the AST into fine-grained pieces in Git (for example, store each AST node or function as a separate Git blob, perhaps organizing them in a directory tree that mirrors the AST), or do we treat the entire AST of a file as one blob (similar to how the entire file text is one blob in normal Git)? This has huge implications. Many small objects could, in theory, let Git reuse unchanged subtrees between commits. For example, if only one function changed, other functions' AST nodes remain identical and their blobs wouldn't need to change or be stored again. This is somewhat analogous to how a binary diff might reuse content, but at a semantic level. However, Git's architecture is not optimized for extremely large numbers of tiny blobs. A single source file might have thousands of AST nodes (consider all expressions, statements, etc.). If each is a blob, a repository with, say, 100 files could easily balloon to tens of thousands of blobs per commit. Git can handle a lot of objects, but performance suffers when you have to manipulate or enumerate them. Operations like checking out a commit involve writing all these objects to the working directory (unless abstracted by a FS). Also, Git's object store and packfiles might handle large blobs more efficiently than zillions of tiny ones (which have overhead). As a data point, having over ~100k files in a repository can slow down operations noticeably, and hitting millions of objects can become a serious bottleneck . Another issue: if we mapped AST nodes to the Git tree structure, the depth of the tree might become very large (e.g., nesting of AST, each node a directory with children as subdirectories/files). Deeply nested trees could hit path length limits or performance issues in Git as well. On the other hand, one large blob per file's AST means we lose the granularity of internal reuse – a small change in the file means the entire blob is considered changed. Git's delta compression might still store it efficiently (Git might delta-compress the new AST blob against the old one, which could work if the textual serialization has similarities), but that's not guaranteed to catch semantic similarity like a move. Essentially, a move of a function might look like a large deletion and insertion in the AST JSON, preventing a small delta storage. The trade-off here is between complexity vs. potential storage efficiency. For MVP we'd lean to the simpler one-blob-per-file approach. The downside is possibly larger repository size and diffs that don't explicitly call out moves (they'd appear as block changes in the serialized text). However, given that Git can compress successive versions, the actual storage might not explode unless the serialization is highly sensitive to position changes. If repository size does become a problem (e.g., JSON AST is much bigger than source code text), we might consider a more compact serialization (binary) or enabling Git LFS for such blobs (though LFS is more for large binaries, not numerous small ones). Summary: We likely trade away the idea of fine AST object granularity in favor of manageable performance. That means intentionally not leveraging Git's object model to its fullest semantic extent, to avoid the "many small files" pitfall. We should monitor how big the AST representations get – including whether including comments/whitespace makes them larger than original code. (It might: JSON with tree structure and duplicated key names could be 2-5× the size of the code text). This is a space/time trade-off: we consume more space and maybe network bandwidth for clone/push, in order to keep the design simpler. If that becomes an issue, one could explore compression or splitting methods later.
• AST Fidelity vs. Simplicity: One major trade-off is how faithfully the AST represents the original source. A high-fidelity (or concrete) AST would include every detail: whitespace, comments, exact formatting, maybe even syntactic sugar exactly as written. A low-fidelity (abstract) AST includes only semantic content (structure, keywords, identifiers, literals) and perhaps minimal spacing needed for parsing. The more faithful the AST, the more complex it is (since we have to include non-semantic tokens). The more abstract, the easier it is to ignore irrelevant changes – but then you risk losing information that may be important to someone. For instance, comments are not part of a classic AST, but losing them is unacceptable – they carry meaning for developers. So we must at least attach comments to the AST nodes or have a mechanism to preserve them. Many Tree-sitter grammars do capture comments as distinct nodes or as "extras." We'd need to ensure we keep those in the stored AST. Whitespace and formatting is trickier: ideally, we'd like to ignore it for diffs (so reindentation or line breaks don't show up as differences), but we might want to preserve it so that if a developer has particular formatting in one part of the code, it isn't completely reformatted when they get it back. This suggests a lossless AST (concrete syntax tree) representation internally, combined with a diff algorithm that knows to skip over formatting nodes when presenting changes. It's a delicate balance. Many AST-based tools take the approach of normalizing or pretty-printing code – sacrificing original formatting. For example, the original proposal that inspired this, from a Prettier issue, suggested that if the AST is the source of truth, "Prettier would need to run on both ends" to present readable code . In other words, always format the code when showing or before saving. That solves consistency (deterministic pretty-print) but discards any manual formatting nuances. If the team is already on board with an autoformatter (like many are with Prettier, gofmt, Black, etc.), this may be acceptable or even desirable (every commit is automatically formatted). But if not, this could be a controversial trade-off. The determinism of pretty-printing is another aspect: we must ensure that formatting the AST yields the same output every time (no arbitrary variation). Good code formatters are deterministic given the same AST, so that's usually fine. But consider if the AST doesn't contain something like the exact number of blank lines or a specific alignment – the pretty-printer might choose a default. That could lead to a scenario where a file is parsed (losing alignment info) and then printed differently, introducing a diff where the code content is the same but spacing changed. To avoid such "flip-flop" diffs, we either have to preserve such info or accept that the system enforces one way. Determinism also matters for hash consistency: if the AST serialization or printed code can vary in ordering (for example, iterating over a map of AST nodes could yield nondeterministic order), we must impose an order. We likely will use the source order of nodes, which is natural, but any data structures used in serialization must be consistent.
Storage of AST vs. text: Another trade-off is whether to keep the original source text at all. One could imagine storing both the AST and the original text (perhaps the text as a blob for fidelity, and AST for diffs). But that duplicates data and risks inconsistency if not handled carefully. It also would bloat the repo. The likely plan is to store only one canonical form. If we choose AST, then fidelity issues come to forefront (as discussed). If we chose to store text and just use AST for diff/merge behind the scenes (like a supplemental index), that might maintain fidelity easily but then you lose the benefit of versioning the AST itself (plus merges would still ultimately produce text, which might not resolve conflicts as cleanly unless you intervene). Given "Git AST" implies the AST is stored, we accept that we either lose some fidelity (line breaks, etc.) or we encode it in the AST. Perhaps a middle ground: store AST plus tokens needed to exactly regenerate original. Some systems call this a concrete syntax tree or an AST with formatting annotations. This would mean our serialization includes placeholders for whitespace or an array of tokens in each node. This complicates diffing (because trivial whitespace changes would now show up unless our diff algorithm is aware to ignore them). It's a complex design choice: either enforce uniform formatting (simpler, but a trade-off that might alienate some users or edge cases) or attempt a lossless AST (harder to implement and slower, but no data loss).
Trade-off decision: For an initial system, it might be pragmatic to sacrifice custom formatting in favor of deterministically pretty-printed code. That greatly simplifies storage (only store the AST of semantics) and diffing (no irrelevant nodes). The cost is that all code in the repo will be reformatted to a standard style on commit. If the user base is fine with that (many projects are), it's acceptable; if not, it's a show-stopper. This is somewhat analogous to how Prettier works – teams accept that on commit their code is auto-formatted. Git AST could piggyback on that cultural shift. We just need to document that clearly. Comments, of course, must still be preserved in the AST and output (the pretty-printer must handle them). Pretty-printers like Prettier do preserve comments and placement reasonably, so using them is viable. The determinism is given by the formatter's rules. This choice trades away the flexibility of arbitrary formatting in exchange for simpler implementation and cleaner diffs.
• Architectural Bottlenecks: The pipeline from editing code to storing an AST commit involves multiple heavy steps: parse, serialize, diff, print. Each of these can become a bottleneck for large projects. Some specific concerns:
• Parsing speed: Tree-sitter is efficient, but parsing thousands of files for a commit (say a bulk branch merge) could be slow. We can optimize by parsing only changed files, not the whole tree on each commit. So the design should track which files' content changed and re-parse just those. If using a filter driver, Git can pass just the file content to the filter on commit. This limits the scope. If changes are widespread (like find-replace in many files), the commit operation will involve parsing many files, which could be slower than a normal git commit (which just blits data to disk). The backend Git storage of the resulting blobs should be fine; it's the parsing overhead that is new. Possibly multi-threading could parse files in parallel if needed.
• Merge conflict resolution overhead: In a normal text merge conflict, the output is conflict markers in the file which the user then fixes manually in a text editor. In AST merge, if we attempt to auto-merge and succeed, great; but if we cannot (true conflict), we need to present the conflict to the user. How? Possibly by falling back to text conflict markers on the source (meaning we'd have to generate the merged file with conflict markers in code form). Or we develop a custom conflict UI. Either way, it's more involved. If merges happen often, the system's ability to handle them quickly is crucial. A poorly performing merge (taking many seconds per file due to complex AST matching) could frustrate users. We might consider limiting AST merge to simpler scenarios at first and default to Git's normal merge for tough cases (with maybe a warning). This is a trade-off of completeness vs. reliability.
• Git metadata overhead: Using Git as a backend means we inherit some Git limitations. For example, each file's content is identified by a SHA-1/OID. If we frequently make tiny changes, Git is very good at storing deltas, but our content is not line-based text, so diff algorithms might not find optimal deltas. However, Git's delta storage works on binary data too, so it might still achieve good compression if AST serializations are similar. A concern is the pack file pressure: many objects (blobs) and their deltas might make git gc expensive. But these are more long-term scaling issues; for moderate repo sizes it might be fine.
• Large binary or non-code files: Not all files in a repo are code. We need to decide how to handle images, binaries, generated artifacts, etc. Likely, we identify non-supported file types and just store them as binary blobs unchanged (like normal Git). But then our system must allow mixing AST-managed files and normal files. For example, a repo might have a .png image – our filter should ignore it (no parse). Or a Markdown/README – which we might treat as plain text (or parse as AST of Markdown? That's out of scope likely). So, design-wise, we'll maintain a list of extensions or languages we handle. Files that don't match are stored as is (maybe flagged to skip any AST processing). This is fine, but a corner-case: what if someone deliberately adds a file in a supported language that has syntax errors – we must handle that scenario as discussed.
• Maintainability of Parsers and Printers: Using Tree-sitter means we are outsourcing the heavy lifting of parsing to a community-maintained grammar for each language. This is great for rapid start, but it introduces a dependency maintenance chore: Tree-sitter grammars need updates as languages evolve. E.g., when a new JavaScript syntax feature is added (say, a new operator or keyword), the Tree-sitter-js grammar must be updated. If our tool lags behind, it will fail to parse files using the new syntax. We'll need a process to update the grammars regularly and test that nothing breaks (especially our AST serialization format, which might need adjustments if the grammar introduces new node types). There is some fragility: Tree-sitter grammars sometimes have bugs or inconsistencies. We might run into cases where valid code doesn't parse due to a grammar bug – then we either wait for an upstream fix or contribute one. For less common languages, the grammar could be unmaintained, meaning if a user's codebase uses a bleeding-edge version of that language, our tool might not support it. This is a trade-off: support breadth vs. reliability. We might choose to officially support a limited set of languages (the ones we can keep up with).
Another maintainability point is the pretty-printers. If we rely on external formatters (Prettier, Black, etc.), we need to track those as well. Changes in a formatter could potentially change how code is output (though usually they avoid oscillating on formatting). We'd likely pin versions to keep determinism. In case we implement custom printing, that's code we have to adapt whenever the language grammar changes (e.g., a new syntax form means updating the printer to handle that AST node or else it might crash or drop it).
Parser upgrade cadence vs. repository history: An interesting corner-case arises when the language evolves. Suppose a new syntax is introduced, and the Tree-sitter grammar is updated. The same source file might produce a different AST shape before and after the update (maybe they changed how a construct is represented in the AST). This could mean that if we reparse old commits with the new parser, we'd get a slightly different AST serialization (even though the text is the same). That's a problem if we ever need to ensure consistency – ideally, the AST stored in each commit remains valid even as parsers change. One way to mitigate is to not reinterpret old commits' content – i.e., the AST was stored at commit time and we never need to regenerate it from text. As long as we keep the original serialized AST, it's fine. But what if we want to reparse an older version (say, for a diff or merge base) using the current parser? If grammar changed significantly, we might mis-merge. This is an edge scenario, but it points to a general trade-off: lock parser versions per repo or per commit vs. always use latest. Possibly we embed a version tag in our data so that if grammars are not backward compatible, we know how to handle it (maybe even keep the old parser around for those commits). That's heavy, though. Alternatively, ensure grammar changes are backward compatible in terms of AST structure (not always under our control).
Given these issues, maintainability is a serious consideration: The Git AST system introduces an ongoing maintenance overhead more akin to a compiler project than a typical VCS tool. We'd essentially be maintaining a multi-language parser suite. This is a trade-off that must be acknowledged – it's no longer "just text" which works universally; it's "structured data" that must be kept in sync with language definitions.
• Pretty-Printing Determinism and Idempotence: We touched on determinism – using a fixed algorithm ensures the same code always prints the same way. But we should also consider idempotence: if we parse and then print code (with our chosen approach), and then parse it again, do we get the same AST? Ideally yes – that would mean printing didn't introduce any oddities. If we use a well-behaved formatter, this should hold (especially if the formatter is basically the inverse of the parser modulo formatting). If not, it could be an insidious bug source: imagine code that, when printed, changes in a way that if parsed again results in a slightly different AST structure (maybe some optional syntax gets filled in, etc.). That could lead to a scenario where committing code twice changes it the second time even without user edits. We must strive to avoid that by design (pick representations that don't do that, or run a check in testing). This is more of a consistency constraint.
• Architectural Flexibility vs. Determinism: Another trade-off is whether developers can configure aspects of the AST generation. For example, can they choose their own code style (if we allowed different printing preferences per user)? If we want that (like the idea each user sees their preferred style), then the printed code is not canonical – it's personalized. That means the AST in storage must be style-agnostic and we do not simply store one formatted version. It suggests a model where the AST is the single source of truth (with no formatting), and the style is applied on the fly for each user view. This is conceptually cool (everyone works in their style, conflicts of style disappear). But to implement that, we likely need the FUSE or editor integration and the ability to apply a style at view time. It also means the build system should not depend on those styles (which it wouldn't if semantics are unchanged). We mention this here as a trade-off between a deterministic single representation vs. a flexible presentation layer. The more flexibility we allow (multiple pretty-prints), the more complexity in the tooling (since now each client might have to reprint code on the fly). For sanity, the MVP/initial design would treat the printed code as deterministic and same for everyone – effectively one style to rule them all. That's an easier architecture to manage, at the cost of not fulfilling the "each dev has own style" dream. That dream could be a later enhancement if ever.

In summary, the Git AST architecture must carefully choose between fidelity vs. simplicity and granularity vs. performance. Likely decisions are: store one blob per file AST (to avoid object explosion), favor a deterministic canonical code format (to avoid needing to track every whitespace detail), and accept that we'll maintain a set of parser/formatter tools over time. These choices prioritize stability and feasibility but come with the trade-off that some information (mainly formatting) is standardized away. We also accept some inefficiency in storage (bigger blobs, maybe more processing on commit) to keep complexity lower. These trade-offs need to be clearly justified to users: e.g., "We always auto-format your code – you no longer need to worry about spacing, and diffs won't show formatting noise , but this means you lose any custom manual formatting." Some teams will gladly take that, others might see it as a deal-breaker. It's a design decision that influences adoption (discussed next).

### 4. Usability and Developer Experience Considerations

Changing the fundamental unit of version control from lines of text to AST nodes will significantly impact the developer workflow. Here we analyze how using Git AST might feel to developers, what friction points might arise, and in what cases the approach could hurt developer experience (DX) rather than improve it. The ultimate success of Git AST depends not just on technical merits but on how comfortable and productive developers are when using it.
• Workflow Changes and Cognitive Overhead: The first question is how visible the AST model is to end users. Ideally, we want the experience to be as seamless as Git, or even invisible (with a FUSE mount, developers just edit code and run git commands normally). However, initially it might require using specialized commands or tools (a custom CLI or GUI). This means developers have to learn new commands (gitast commit instead of git commit, etc.) or set up filters to use normal Git. There's an inherent cognitive overhead in introducing a new layer: developers must trust that what they see (pretty-printed code) is faithfully being versioned as AST, and understand that diffs they see might omit things like whitespace changes. Some may find that beneficial (less noise), but others might feel uneasy if they can't see exactly what text changed under the hood. There's also the need to explain the concept of "the source of truth is an AST, not the exact text you wrote." That is a mental model shift. For example, a dev might ask: "If I put two spaces here or align things a certain way, does it matter? (No, it won't be preserved)" or "If I commit code with a syntax error, what happens? (Probably disallowed or stored differently). These are new considerations. The learning curve is not huge in concept, but it's a departure from decades of line-based diff mental models.
Additionally, interpreting diffs might require more from the developer. AST diffs can be presented in familiar formats (side-by-side code with highlights), but if we ever expose a more tree-structured view, that could be foreign. For merges, if the tool says "Conflict in function X: both branches modified it differently," that might actually be clearer than line conflict markers. However, if conflict representation isn't carefully designed, it could confuse (e.g., showing a JSON of AST with conflicts embedded would be awful – we'd have to convert conflicts back into a textual view for resolution).
• Tooling Ecosystem Compatibility: A major friction point is integration with the vast ecosystem of tools that expect text diffs and text files. If we fully commit to AST storage, a naïve use of existing tools breaks. For instance:
• Running git log -p on an AST repository might show patches full of AST JSON gibberish, unless our tool overrides it with a custom diff. So, developers can't rely on standard Git commands for diffs unless we manage to integrate (perhaps via git config diff.driver hooking to our diff).
• Code review platforms (GitHub, GitLab, etc.) expect to display diffs of text. If we push AST commits to GitHub, by default it will show the AST file changes (which are not readable code diffs). This is a huge DX concern: it means out-of-the-box, standard code review workflows break. We'd likely need either an integration (maybe a way to tell GitHub to use an external diff tool – currently not really possible) or a workaround such as storing an extra text representation for the purpose of code review. One idea: keep a mirror branch of formatted source code purely for viewing on GitHub, while the main branch stores AST. But that complicates CI and might confuse contributors. Another idea: some Git hosts allow custom diff algorithms or semantic diff view (GitLab had something for Wikipedia diffs, etc., but not general AST as far as I know). Without first-class support from these platforms, using Git AST in a team might force them to adopt a new review tool or pipeline (maybe using a local tool to review diffs).
• IDEs and editor integrations: Editors rely on files on disk. If we do the FUSE approach, then editors can open files normally and it's fine (they see code text). But if not, say a dev clones the repo and gets AST files, their editor will show JSON or some structured content, not the code. That's not workable. So we more or less must ensure that the working directory a dev interacts with contains actual source code text, not AST. That implies using Git's clean/smudge or a separate export step. If we fail to do that, the DX impact is catastrophic (no one wants to manually decode AST to code just to edit). So likely we will keep the working copy as code for editing convenience – treating AST mostly as an internal storage format. This reduces friction significantly, but it means all editing is done on text and parsed at commit time, which reintroduces potential for parse errors at commit (as discussed) and means the user has to wait at commit or use pre-commit hooks.
• Compilation or testing: If using a FUSE FS, reading the files (source code) for building might be slower. In large projects, compilers reading many files through FUSE could be noticeably slower than reading from a normal disk. That could impact build times – a serious DX degradation. We might mitigate by allowing a local checkout of generated source for build, or caching results.
These performance hits can cause frustration, especially if they break the flow (imagine waiting 5 seconds every commit for the AST filter to run – that might irritate some devs, though others might accept it for what they see as improved diffs/merges).
• Conflict Resolution & Merges – DX Implications: In theory, AST-based merging should reduce the number of conflicts and make merges smoother. That's a positive DX – less time manually fixing conflicts. If Git AST successfully handles, say, function reorders or independent changes in the same function (because it knows they occur in different AST nodes), developers will see fewer conflict markers. That is a clear win. However, we must consider the worst-case when a conflict does happen. Traditional Git will present conflict markers in the file, which, while messy, is something developers are used to resolving with their editor. If our system instead says "Conflict in AST node X", we have to present that in terms of code. Perhaps we could output both versions of the code for that function with markers, similar to today but maybe confined to the function body. If we do nothing special, and just let Git merge the AST JSON and produce a conflict, that would be a nightmare (JSON conflict is far harder to interpret than code conflict). So we must intercept merge conflicts and handle them. Possibly we would integrate with SemanticMerge-like functionality to present a structured conflict resolution UI. But expecting every developer to use a new merge tool UI is a barrier. Ideally, we'd integrate into existing Git merge tooling (e.g., producing a conflict file with markers but perhaps more targeted). This is an area where DX can degrade if not carefully addressed. If a developer encounters a conflict situation that our tool doesn't handle automatically, they might find it more confusing to resolve than a normal git conflict, especially if our output is not straightforward.
• Corner-case Scenarios that Hurt DX: There are certain use cases where AST-based model might actually complicate a developer's life:
• Work-in-progress commits / stashing: As noted, committing incomplete code that doesn't parse might be disallowed. Developers sometimes commit WIP or at least stash it. If our system refuses, the developer has to either finish writing the code or find another workaround (like temporarily disable the filter or store it in a dummy file). This disrupts the ability to checkpoint work frequently. Similarly, git stash might need to stash AST states; if a file is unparseable, does stash fail? Or maybe stash just treats it as is (which might break later when applying if it tries to parse).
• Running diffs on uncommitted work: Developers often use git diff to review what they changed before committing. If our model only diffs AST after parsing, and the file currently has a syntax error, will git diff show anything? Perhaps not, if it can't parse the new version. We might need to fall back to text diff in that case to at least show the changes. That inconsistency (sometimes diff is semantic, sometimes falls back to raw text if file has an error) could be confusing: "Why is this diff showing spaces now?" – "Oh, because my file has a parse error so it's not doing AST diff." This is a cognitive load to remember.
• Rebase and history rewriting: If the user does interactive rebase or uses git bisect, they might be dropping into states where the working copy is an older commit. The filters or FUSE should handle that transparently, but any glitch and it could be a mess. For example, if a commit in the middle has something weird that newer parser can't parse, rebasing through it might fail unless we handle it.
• Collaboration with external contributors: If one developer uses Git AST but others don't (say they share via a normal Git remote), how does that interplay? Perhaps it doesn't at all – everyone on the project must use the same system, otherwise they'll push AST blobs that others see as nonsense. This means adoption typically has to be team-wide from the start (or at least repository-wide). If someone accidentally commits via normal Git bypassing our filter, they might commit raw code text which our system didn't parse – could that break things? Perhaps if our design is robust, it would just treat it as one commit of "some content" and next time someone uses our tool it will parse and commit a replacement. But inconsistent usage will lead to inconsistent results. So there's a risk of process friction: all collaborators need to buy in and set up the environment, which can be a hurdle for new team members or open-source contributors.
• Cases where DX might degrade rather than improve:
• If a team rarely has merge conflicts or is already disciplined with formatting (e.g., they use Prettier and small PRs), the benefits of AST diffs might be marginal. In such cases, the overhead of a new system may outweigh the gains. For instance, if 99% of their diffs are already pretty clean and conflicts only happen in big merges resolved by senior devs, introducing AST might not tangibly improve things but will make every commit slower and require new tooling. Developers could perceive it as over-engineering.
• Debugging: when something goes wrong in the Git AST pipeline (e.g., a file isn't showing up, or a parse produced an unexpected structure), it might be harder for a regular dev to troubleshoot. In Git, if something is weird, you can open the .git file or see the text diff. In Git AST, if, say, a commit seems off, one might have to inspect the AST JSON. Most devs aren't equipped to manually verify AST output. They have to trust the tool or involve its developers to debug. This can create a sense of opaqueness.
• Edge cases with AST updates: Suppose the AST grammar changes and suddenly in a new version of the tool, a certain code pattern is handled differently (maybe previously ignored some minor difference but now marks it as change). Developers might see spurious diffs or need to reconvert things. This could reduce confidence in the stability of diffs.
• Developer Acceptance Risk: A softer factor is whether developers want this model. Some may love the idea of eliminating "stupid conflicts" and not caring about formatting. Others might be skeptical, feeling that it's too much magic or that it could hide important details. For example, some developers actually use whitespace changes deliberately or want to see them (like aligning columns in a config). If those are auto-removed from diffs, they might be annoyed that their deliberate formatting changes are ignored or stripped. Another example: AST diff will treat reordering of functions as no significant change (maybe just an AST move). But sometimes in a code review, seeing a huge block of code moved triggers a discussion (like "why was this function moved? It's hard to tell in a semantic diff because it might not highlight the move clearly if it's purely structural"). A line diff would show a big removal and addition, which signals a refactoring happened. A semantic diff might make it appear minor ("oh, just moved, ignore it"). This could lead to less visibility into large refactorings unless the tool explicitly calls out moves. We'd have to ensure moves are clearly indicated, not just silently handled.

In conclusion, the developer experience will improve in some ways and become more complex in others. Positive impacts include cleaner diffs (no noise from formatting or code moves) and potentially far fewer merge conflicts, which directly saves time and frustration. Those are significant gains: no more arguing about indent changes in PRs, and refactorings not causing merge hell – developers will appreciate that . On the other hand, potential friction comes from the need to use custom workflows or ensure the system is set up correctly in each environment, the slight performance overhead in certain operations, and the adjustment to trusting a "smart" system with their code. There's a risk that if the system fails even occasionally (say, mangles a rare piece of code or has a bug), developers will lose confidence and revert to plain Git. Therefore, DX risk mitigation is crucial: we should provide fallbacks (e.g., the ability to retrieve raw text if needed, or to disable the filter on a problematic file) and excellent documentation of how things work.

Ultimately, if done well, AST-based version control could be largely invisible – developers just notice that diffs and merges are smoother, and they might forget that under the hood it's AST-driven. That's the ideal: all the heavy machinery is hidden behind a familiar interface. But achieving that invisibility (via integration in Git clients, editors, CI, etc.) is a big challenge. If the integration is only partial, developers will definitely notice the seams (like "why does GitHub show weird diffs?"). So the success on a DX front hinges on how well we can integrate or abstract the differences away, and how many of the user's existing habits can remain unchanged.

### 5. Go/No-Go Risks and Key Assumptions

The viability of the Git AST project rests on several key assumptions and requirements. If any of these turn out to be false or insurmountable, the entire approach could become untenable ("no-go"). Here we identify those critical assumptions and failure points:
• Assumption 1: Full AST Fidelity or Acceptable Losses. We assume that the AST can represent everything important in the code. If it cannot (for example, if comments or certain syntactic variations aren't captured), we risk altering code meaning or losing developer intent. A key risk is losing comments or annotations – if our approach didn't store comments, that would be immediately unacceptable (we plan to store them). Another risk is subtle: some languages have semantics tied to formatting (Python's indentation, or line breaks in some configs). If the AST or pretty-printer misrepresents those, the code's behavior could change. We must ensure that for every supported language, the AST->code->AST round-trip preserves semantics exactly (or we explicitly don't support that feature). If this assumption fails – e.g., if we find that it's impossible to round-trip certain code patterns without altering them – then using AST as source of truth is not safe. That would be a show-stopper for those languages or require a complex workaround (like embedding literal text for those parts). What could make this untenable: if any mainstream language feature (like C preprocessor macros or complex templating in code) simply can't be captured well by the AST. For instance, consider C/C++: a preprocessor directive can inject code that isn't visible in the AST at parse time. We might have to decide not to handle preprocessor logic at all (just version the post-PP AST maybe, which is problematic). If too many such cases occur, the AST approach might only work for subset of languages, limiting its appeal.
• Assumption 2: Deterministic Pretty-Print (Stable AST Serialization). We assume that given an AST, we can always serialize it or print it in a stable, deterministic way. If the AST contains elements that are non-deterministic (like hashed in random order), we have to fix an order. If our pretty-printer occasionally produces different output for the same AST (due to some non-determinism or environmental factors), that would wreak havoc on diffs (the system might think something changed when it didn't). We are counting on the fact that by controlling the formatting tool, we ensure determinism. A major risk here is parser or printer non-determinism: e.g., if Tree-sitter's error handling depends on file history or on how it caches, it might produce slightly different AST shapes in different runs. Or if the pretty-printer has options that aren't fully stable (though most formatters are stable by design). If this assumption fails, you get unpredictable results – e.g., commit the same content twice yields different AST or different text, causing ghost diffs. That would severely undermine trust in the system. No-go scenario: if we find that for some reason the pipeline isn't stable (perhaps due to comments moving around, or AST node IDs not consistent), and we cannot easily enforce determinism, then the approach might not reliably work. We'd have to restrict usage or re-architect to include more original info.
• Assumption 3: AST Merge is Good Enough (or Falls Back Safely). A big promise of AST-based VCS is better merge conflict resolution. We assume that we can at least do no worse than Git in merging, and ideally better. A risk is that our merge algorithm might handle many cases, but when it fails, it fails in a worse way than Git. For example, imagine it tries a structured merge and produces a syntactically invalid merged AST (because it combined pieces wrong). The user then gets an invalid file without obvious conflict markers – a potentially confusing situation ("the code doesn't compile, where is the conflict?"). Or, it might silently pick the wrong version of a change if our logic is flawed (causing a semantic change to slip in without conflict). These are dangerous failure modes – at least Git's conflicts force a human to resolve ambiguous cases. Our tool must be extremely careful to either merge correctly or explicitly flag a conflict. If it ever loses code or introduces bugs during merge, that's a catastrophic trust failure. So the assumption is that we can implement merging in a safe manner. If further research or testing shows that automatic AST merges are too unreliable or unpredictable, we might have to drop auto-merge and just use AST for diffs and manual conflict presentation. That would reduce one of the major selling points (fewer merges). If that happens, is the project still worth it? Possibly less so. Tenable if: The merge strategy comes with a guarantee (or at least strong confidence) that it won't silently do the wrong thing. Otherwise, devs will not adopt it for fear of subtle merge errors.
• Assumption 4: Git Storage and Scale Remains Manageable. We assume Git can handle storing ASTs for our project sizes reasonably. If it turns out that the repos grow too large or operations become too slow, the approach might not scale. For example, if an AST-ified repo becomes 3-5× larger than a text repo, and operations like clone or push take much longer, teams might balk. Git is quite efficient, but it's tuned for line-oriented text where diffs compress well. We are somewhat stepping outside that expectation. If repository bloat or performance issues emerge (especially with many small objects, which we plan to avoid, but if we didn't it would be a likely no-go), we might have to abandon Git backend or significantly alter our approach (e.g., use Git LFS or a database). There's also a hard limit scenario: GitHub and other hosts have limits (e.g., file size, repo size). We likely won't exceed those unless doing something extreme, but it's to watch (e.g., GitHub often warns about repos with huge numbers of files or very large files >100MB; an AST of a massive file might be >100MB in worst cases?). Also, the number of objects could affect push/pull times – if every commit touches large binary blobs, delta negotiation might strain. If these issues make collaboration slow, the approach might be deemed impractical. No-go condition: the first pilot on a moderately sized codebase shows severe performance degradation (e.g., every commit takes 30 seconds, repo size doubled in a month). That would likely kill enthusiasm.
• Assumption 5: Team Willingness and Ecosystem Fit. We assume that teams are willing to adopt a new workflow or tool if it demonstrably improves their life. But if adoption requires too much change (everyone has to use a custom Git wrapper, continuous integration needs adjustment to handle the AST content, etc.), it might face resistance. A risk is that outside of a controlled environment, the approach doesn't integrate with common platforms. For example, can we integrate with GitHub? If not, any team reliant on GitHub PRs and reviews might say no-go. We might assume that "maybe in the future Git platforms will support semantic diffs." If that doesn't materialize, our system could remain an island. Another assumption is that all developers on a project can and will configure their environment to use Git AST correctly. If one person doesn't (or can't, e.g., a drive-by contributor who isn't aware), they might introduce inconsistencies. That could degrade the repo or force maintainers to do extra work (like converting their contribution). If that happens often, it's a huge process burden. No-go scenario: if it turns out that using this requires isolation (you can't effectively collaborate with external folks or use normal Git tools), many might find it not worth it despite its advantages. Essentially, the approach might not gain critical mass and thus fail not for technical reasons but for social/compatibility reasons.
• Assumption 6: Tree-sitter (or chosen parser) can handle all project code. We touched on grammar maintenance, but another risk is robustness. Real-world code can be messy: incomplete code in the middle of edits, or code with conditional compilation (e.g., #ifdef blocks that break the parser depending on platform), or even generated code. If Tree-sitter can't parse a file (maybe due to a grammar bug or because the code is extremely large), what then? Git AST would either skip it or treat it as binary. If that file is important, it's a gap. We assume Tree-sitter will work for the majority of code. Tree-sitter does have error recovery, meaning it can produce an AST even if there are errors, but the quality of that might be questionable. For languages like C++, which rely on a preprocessor, Tree-sitter parses them without running the preprocessor (it parses what it sees). This means certain constructs might appear strange in the AST. For instance, an #include directive or a macro call is not resolved; the AST might just see it as a special node or skip it. This could impact how meaningful an AST diff is (the AST might not fully represent semantics if macros are not expanded). We assume for now that's acceptable (we diff the literal code structure, not macro-expanded code). However, if a lot of important changes happen via macros, AST diff might miss that or show them weirdly. If any language's essential features aren't well-handled, using this system for that language is risky. No-go example: "We tried it on our C++ project, but every second commit fails because Tree-sitter can't parse some template-heavy code." That team would likely abandon Git AST for being too unreliable.
• Trust and Debuggability: This is more subjective, but worth noting: the approach assumes developers will trust the AST system to not lose or corrupt their code. If any incident occurs where code gets lost, corrupted, or mis-merged, trust will evaporate. Traditional Git, for all its flaws with conflicts, is trusted to never spontaneously alter your code – it just might present conflicts you have to fix. If Git AST ever did something like drop a comment or rename an identifier incorrectly during a merge, it would be a severe breach of trust. The project essentially has one shot to prove itself in a team's workflow; an early bad experience could lead to a permanent "no-go" from that team. Mitigating this means extensive testing and possibly a staged rollout (maybe initially just use it for diff viewing, not actual commits, to build confidence).

In summary, the approach depends on a constellation of things working properly: parsers must parse, printers must print consistently, Git must handle the content efficiently, and developers must buy in. The most glaring "approach would be untenable if..." conditions include:
• If the system cannot preserve code semantics and important artifacts 100%, it's a non-starter (we can't lose data).
• If the system introduces unacceptable performance overhead or storage bloat that can't be optimized, it would fail in practice.
• If it fails to integrate with essential tools (code hosting, CI, IDEs) and thus requires too many workarounds, many teams would not commit to it.
• If the core benefit (fewer conflicts, cleaner diffs) doesn't clearly manifest or is overshadowed by new problems (like parse errors or weird conflicts), then the value proposition falls apart.

One key assumption that underpins all: that code diffs and merges are a pain point worth solving with this complexity. If in reality teams find their current text-based workflow "good enough," convincing them to switch would be hard – making the effort moot. So it hinges on the pain point being significant and this approach actually alleviating it without adding equal pain elsewhere.

### 6. Recommendations and Potential Pivots (Optional)

Considering the above evaluation, the "Git AST" concept is powerful but faces non-trivial hurdles. Depending on what the primary goal is (better diffs, easier merges, etc.), there might be alternative architectures or scoped-down approaches that achieve much of the benefit with less risk. Here are a few recommendations and possible pivots:
• Start as a Diff/Merge Enhancement, not a Full VCS Replacement: One approach is to not immediately store ASTs in Git, but use AST parsing to assist diffs and merges on top of the existing Git storage. For example, one could develop a tool that hooks into git diff and git merge as a driver. When a merge is initiated, it parses the files and tries a semantic merge (like SemanticMerge does); if successful, great – if not, it falls back to a standard conflict. Similarly, for diffs, you could alias git diff to a script that calls difftastic for supported languages to display the diff, without changing the underlying commits. This way, developer workflow stays the same (same Git data), but they get improved diffs in reviews (via a diff tool integration) and fewer conflicts (via a custom merge driver). This is much easier to adopt incrementally: teams can try it without converting their whole repo. Over time, if this proves effective, you might then introduce storing ASTs if needed for further benefits. Essentially, this is a more conservative approach that captures 80% of the value (semantic awareness) with 20% of the change. The downside is you don't get some theoretical benefits like per-user formatting views or eliminating text diffs entirely – but those might be overkill initially. This pivot acknowledges the risk of changing storage and avoids it until proven.
• Leverage Git's Clean/Smudge Filters for Transparency: If we do want to store ASTs but minimize friction, using Git's built-in content filtering might be smarter than a separate filesystem. Git allows configuring a clean filter (to transform files on commit or before adding to index) and a smudge filter (to transform files on checkout). We could set up, for each supported file type, a clean filter that parses the code and outputs a serialized AST (possibly in a compressed form to reduce size) and a smudge that does the reverse (pretty-prints back to code). This way, developers still edit code normally in the working copy, and if they look in .git/objects they'd find AST content, but they rarely need to. This approach has been discussed in theory (for example, storing code in AST form and pretty-printing on checkout was suggested as a plugin idea) . The advantage is you can use normal Git commands; the filters will apply automatically. The challenge is performance – filters run per file, so committing a lot of files will run many parse processes. But Git does have a filter process interface (to keep a process alive and reuse it). We could implement a filter driver that keeps Tree-sitter parser in memory to handle many files efficiently. This route avoids needing a custom Git distribution or special FUSE mounts. However, filter drivers need to be configured in each clone (via .gitattributes and filter setup in config), which is okay if part of repo config. One must also ensure all collaborators have the filter tool installed, or else they'll commit raw AST or raw code inconsistently. As a pivot, this is basically how to implement Git AST within Git's framework rather than around it. It might simplify some integration (e.g., CI could potentially just check out normally and get code text, as smudge will run). It's worth considering because it uses Git's strengths (index and working copy separation) to our advantage.
• Focus on a Niche to Prove Value: To reduce scope and increase chances of success, target a specific use case or language where this shines. For example, perhaps start with a Python-specific AST version control, or for Java, etc. Certain languages (like those without widespread auto-formatting, or those with frequent merge conflicts due to significant whitespace) could benefit more. By narrowing focus, you manage the grammar and printing for one language deeply, making it robust, rather than juggling ten languages. If that experiment yields significant DX improvement for that language's developers, it provides evidence to expand to others. Conversely, if it doesn't prove out, better to find out on a small scale. This is more a strategy than a technical pivot, but it's relevant.
• Rethink the Backend (if Git proves limiting): If along the way we hit fundamental issues with using Git (maybe performance with large ASTs, or inability to integrate nicely with required features), consider a custom backend or an existing alternative. For instance, using an existing database or content store that is built for tree-structured data might be more natural. There are versioned graph or JSON stores (maybe something like Datomic or a CRDT-based system) that could store AST nodes with IDs and track changes. That's basically writing a new VCS. We could then build a thin compatibility layer to import/export to Git for interoperability (similar to how some tools have a mirror to Git). This is a heavy pivot (basically building a new VCS from scratch), not recommended unless absolutely needed. But if Git's model (files and lines) is too mismatched, it might actually be cleaner to design a purpose-built store for ASTs. That said, initial attempts should try to work within Git before deciding it's impossible.
• Use an Intermediate Representation (IR) for Multi-Language or Language-Independent Features: This is an exploratory idea: if supporting many languages is daunting because each has different ASTs, one could consider translating all code into a common intermediate form. For example, something like Microsoft's MSIL/CIL (for .NET languages) or LLVM IR for C-family, or even a higher-level universal AST (some research projects tried this, like GumTree's "abstract AST for all langs" mention or SourceML). If such an IR existed, one could store that instead of language-specific AST. But realistically, a single IR for all languages that preserves full semantics is not there yet (and essentially as hard as writing all parsers anyway). Another angle: use a language server's AST – many languages have language servers or compiler APIs (e.g., Roslyn for C# has a rich AST that is lossless and can round-trip). Perhaps for those languages, hooking into the compiler's own AST could be more robust than Tree-sitter. That could improve fidelity (Roslyn, for instance, keeps everything including trivia). A pivot could be per-language: use the best available parser/IR. For some, Tree-sitter; for others, native compiler AST. The downside is it's heterogeneous and harder to maintain consistency, but it might reduce edge-case parse errors. This is more a fine-tuning pivot rather than a structural one.
• Dropping FUSE Plan Unless Needed: We recommend not using FUSE unless user testing shows that everyone demands editing different personal styles simultaneously or something that truly requires dynamic views. FUSE complexity is high, and many benefits can be achieved without it (especially if using Git filters as above). One can achieve a "transparent-ish" experience with filters and a well-documented setup. FUSE would add OS-specific issues (macOS, Linux, Windows each have their own FUSE story or lack thereof), making cross-platform support a nightmare for a VCS tool. It's probably wiser to avoid that path unless absolutely required for an optional feature.
• User Interface for Diffs/Merges: Provide a good UI (could be command-line textual, or if possible, GUI) for viewing AST diffs and resolving AST merges. A small but helpful addition could be a tool to visualize the AST itself (for debugging or curiosity) – sometimes seeing the tree helps understand what the tool is doing. If users can easily inspect what the AST looks like for their code, they might trust it more or catch issues. It might even aid in conflict resolution (like a 3-pane AST merge view: base, change1, change2 with differences highlighted in the tree). This is a bit pie-in-sky but could differentiate the experience positively.

In essence, the recommendation is to incrementally de-risk the project: focus on demonstrating the tangible benefits (semantic diff/merge) in a minimally invasive way first. If those benefits are real and significant, it builds momentum to justify deeper changes (like fully storing ASTs). If some pieces (like multi-language support) turn out to be too costly for too little gain, consider limiting scope or waiting until more resources are available.

Lastly, keep an eye on academic and industry trends. The concept of AST-based versioning has been around in research for a while; there might be new developments (e.g., projects combining version control with structured editing, or companies like Google with their monorepos exploring smarter merge tools). Being open to integrating such developments or pivoting if a better approach emerges (for example, some have suggested operational transformation or CRDTs on ASTs for real-time collaboration – that's beyond this project's scope but related). If Git AST struggles, perhaps a CRDT approach might ironically handle some of these merge issues differently (but that's a whole different paradigm).

Conclusion: The Git AST project is ambitious and addresses real pain points. Our evaluation shows that while it's technically feasible, it carries a high complexity overhead and several critical risks. A cautious, phased implementation and a willingness to adjust the plan (e.g., using Git as-is with AST-assisted operations before committing to AST-as-storage) will improve the likelihood of success. By learning from existing tools (difftastic, SemanticMerge, etc.) and addressing the practical DX issues from the start, the project can avoid being an academic curiosity and become a valuable engineering tool. Proceeding with clear awareness of the constraints and trade-offs we've outlined will help ensure that the end result truly improves developer productivity rather than introducing new frustrations.

Sources: 1. P. Tourani et al., "Fine-Grained and Accurate Source Code Differencing: GumTree" – explains limitations of line diffs (no move detection) and benefits of AST differencing . 2. Wilfred Hughes, Difftastic – README and manual (2022), a structural diff tool using Tree-sitter; notes on language support and performance . 3. SemanticMerge by Plastic SCM – Endjin blog review (2014) describing semantic merge capabilities (detecting moves, renames, etc.) and supported languages . 4. Hacker News discussion "What if Git worked with programming languages?" (2021) – user comment proposing a FUSE filesystem for AST storage . 5. Baz.ai blog, "Why Your Code Gen AI Doesn't Understand Diffs" (2023) – highlights how Git diffs lack semantic info (treat refactors as separate changes) . 6. Canva Engineering Blog, "We Put Half a Million Files in One Git Repository" (2022) – discusses Git performance issues with very large numbers of files; notes performance impact beyond ~100k entries in directories . 7. Pijul Dev Forum (2018), "AST-level diffs and merges" – community discussion on how AST diffs could resolve conflicts that line-based systems struggle with (e.g., variable rename) . 8. GitHub – afnanenayet/diffsitter – an AST diff tool similar to difftastic, demonstrating interest in AST diffs and confirming the approach of ignoring formatting via Tree-sitter . 9. Hacker News discussion of diffsitter (2021) – mentioned the desire for GitHub to support AST diff in PR GUI as an option . 10. Research paper "IntelliMerge: Refactoring-aware merging" – found to reduce merge conflicts by ~59% vs standard merge .
